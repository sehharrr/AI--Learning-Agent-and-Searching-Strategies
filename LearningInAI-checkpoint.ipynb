{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac0359f-8af5-433c-8ee1-97af99b0c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Data manipulation and analysis\n",
    "import numpy as np #mathematical function and computing\n",
    "from sklearn.model_selection import train_test_split #split array etc\n",
    "from sklearn.metrics import classification_report #generate report\n",
    "from sklearn.metrics import confusion_matrix #matrix to avaluate accuracy\n",
    "from sklearn.metrics import accuracy_score #compute accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7750ee-0400-4fbd-9aab-2838745b0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, learning_rate, n_iterations=2000, n_hidden_units=5):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.n_hidden_units = n_hidden_units #hidden layers of MLP\n",
    "        self.weights_input_hidden = np.random.uniform(low=-0.1, high=0.1, size=(X.shape[1], self.n_hidden_units))\n",
    "        #weights for connection between inner and hidden layer\n",
    "        self.weights_hidden_output = np.random.uniform(low=-0.1, high=0.1, size=(self.n_hidden_units, len(np.unique(y))))\n",
    "        #weights for connection between hidden output layer\n",
    "\n",
    "    def sigmoid(self, x): #activation function 1\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x): #activation function 2\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def tanh(self, x): #activation function 3\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def sigmoid_derivative(self, x): #derivation for sigmoid\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "        \n",
    "    def fit(self, X, y, activation_function='sigmoid'):  #train the neural network\n",
    "        for _ in range(self.n_iterations):\n",
    "            if activation_function == 'sigmoid':\n",
    "                activation_function = self.sigmoid\n",
    "                activation_derivative = self.sigmoid_derivative\n",
    "            elif activation_function == 'relu':\n",
    "                activation_function = self.relu\n",
    "                activation_derivative = self.relu_derivative\n",
    "            elif activation_function == 'tanh':\n",
    "                activation_function = self.tanh\n",
    "                activation_derivative = self.tanh_derivative\n",
    "            \n",
    "            hidden_layer_input = np.dot(X, self.weights_input_hidden) #hidden layer input and output\n",
    "            hidden_layer_output = activation_function(hidden_layer_input)\n",
    "\n",
    "            output_layer_input = np.dot(hidden_layer_output, self.weights_hidden_output)\n",
    "            output_layer_output = self.sigmoid(output_layer_input)\n",
    "\n",
    "            error = y - output_layer_output #computes error\n",
    "            d_output = error * self.sigmoid_derivative(output_layer_output)\n",
    "\n",
    "            error_hidden_layer = d_output.dot(self.weights_hidden_output.T)\n",
    "            d_hidden_layer = error_hidden_layer * activation_derivative(hidden_layer_output)\n",
    "\n",
    "            self.weights_hidden_output += hidden_layer_output.T.dot(d_output) * self.learning_rate\n",
    "            self.weights_input_hidden += X.T.dot(d_hidden_layer) * self.learning_rate\n",
    "\n",
    "    def predict(self, X): #function to make predictions\n",
    "        hidden_layer_input = np.dot(X, self.weights_input_hidden)\n",
    "        hidden_layer_output = self.sigmoid(hidden_layer_input)\n",
    "\n",
    "        output_layer_input = np.dot(hidden_layer_output, self.weights_hidden_output)\n",
    "        output_layer_output = self.sigmoid(output_layer_input)\n",
    "\n",
    "        return np.argmax(output_layer_output, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd7da81-a4f3-414b-912e-17d1805dd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Gradient Descent Delta Rule algorithm\n",
    "class GradientDescentDelta:\n",
    "    def __init__(self, learning_rate, n_iterations=2000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = np.random.uniform(low=-0.1, high=0.1, size=X.shape[1])  # Small random initial weights around zero\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_iterations): #compute error, weights\n",
    "            errors = y - self.predict(X)\n",
    "            update = self.learning_rate * np.dot(X.T, errors)  # Update based on the transpose of X\n",
    "            self.weights += update\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.sigmoid(np.dot(X, self.weights)) >= 0.5, 1, 0)\n",
    "\n",
    "    def accuracy(self, X, y): #tells the accuracy of gradient rule\n",
    "        predictions = self.predict(X)\n",
    "        correct = np.sum(predictions == y)\n",
    "        return correct / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c43c0f-faab-45a7-8b06-517577254f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Iris dataset from iris.data\n",
    "iris_df = pd.read_csv('iris.data', header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "\n",
    "# Convert species names to numerical labels\n",
    "iris_df['species'] = iris_df['species'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = iris_df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "y = iris_df['species'].values\n",
    "\n",
    "# Split the dataset into training and testing sets (80/20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeec7331-f988-4312-8606-d5ac48b0dc1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create an instance of the algorithm and fit the data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m gd \u001b[38;5;241m=\u001b[39m GradientDescentDelta(learning_rate)\n\u001b[0;32m      3\u001b[0m gd\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m      4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m gd\u001b[38;5;241m.\u001b[39maccuracy(X, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an instance of the algorithm and fit the data\n",
    "gd = GradientDescentDelta(learning_rate)\n",
    "gd.fit(X, y)\n",
    "accuracy = gd.accuracy(X, y)\n",
    "activation_functions = ['sigmoid', 'relu', 'tanh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "554ca733-147d-4670-b4ca-f9aa468255a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, mlp_predictions)\n",
    "class_report = classification_report(y_test, mlp_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71d9db19-d422-470a-a2d8-ce428d54a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter learning rate:  0.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0 10]\n",
      " [ 0  0  9]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.37      1.00      0.54        11\n",
      "\n",
      "    accuracy                           0.37        30\n",
      "   macro avg       0.12      0.33      0.18        30\n",
      "weighted avg       0.13      0.37      0.20        30\n",
      "\n",
      "\n",
      "Multilayer Perceptron Results:\n",
      "Predictions: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_7200\\2910786651.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with sigmoid activation function: 30.00%\n",
      "\n",
      "Accuracy with relu activation function: 56.67%\n",
      "\n",
      "Accuracy with tanh activation function: 93.33%\n",
      "\n",
      "Gradient Descent Result:\n",
      "Accuracy: 33.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_7200\\2910786651.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "# Ask for user input\n",
    "learning_rate = float(input(\"Enter learning rate: \"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "print(\"\\nMultilayer Perceptron Results:\")\n",
    "mlp_predictions = mlp_model.predict(X_test)\n",
    "print(f\"Predictions: {mlp_predictions}\")\n",
    "# Evaluate model performance on testing set for each activation function\n",
    "for activation_function in activation_functions:\n",
    "    mlp_model = MLP(learning_rate)\n",
    "    mlp_model.fit(X_train, np.eye(3)[y_train], activation_function)\n",
    "    mlp_predictions = mlp_model.predict(X_test)\n",
    "    mlp_accuracy = accuracy_score(y_test, mlp_predictions)\n",
    "    print(f\"\\nAccuracy with {activation_function} activation function: {mlp_accuracy:.2%}\")\n",
    "\n",
    "print(\"\\nGradient Descent Result:\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa2016-7e4e-4978-ad13-0394e75120c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
